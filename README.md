# CE-LoRA: Consistent Person Synthesis by Exploring the Model's Spatial Consistency

[![Hugging Face](https://img.shields.io/badge/HuggingFace-Per400k-yellow?logo=huggingface)](https://huggingface.co/datasets/a1557811266/Per-400k)

## News

* **2025.05.27:** Repository created. Code and dataset coming soon.
* **2025.05.27:** Per-400K dataset publicly available for download.
---

## Per-400k Dataset

This dataset is designed for training models that generate person-consistent images: given a reference person image, the model learns to create new images of the same individual (with the same clothing and appearance), but in different backgrounds or performing different activities.

Each entry in the dataset JSON file is a dictionary containing paths to the original generated image, its two sub-images (left and right), and prompts describing the differences between these paired images.

**The dataset contains a total of 470,664 pairs of person images, resulting in double that number of triplets for training.**

<div style="text-align:center;">
    <img src="https://cdn-uploads.huggingface.co/production/uploads/655cc83c2735108d4976118f/pJL19k5_VN7oRnNVr2WwZ.png" 
         alt="Examples and main text in the Per400K dataset" 
         width="75%" />
</div>

---

## Structure of the JSON File

Each item (dictionary) in the JSON file has the following keys:

| Key                     | Description                                                                                                                                                                                                                                                  |
| ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `image_path`            | Path (relative to the base directory) to the original image generated by the model.                                                                                                                                                                          |
| `image_path_left`       | Path (relative to the base directory) to the left sub-image, cropped or split from the original image.                                                                                                                                                       |
| `image_path_right`      | Path (relative to the base directory) to the right sub-image, cropped or split from the original image.                                                                                                                                                      |
| `Right Relative Prompt` | A prompt that describes the right sub-image **relative to the left sub-image**. This means: given the context of the left image, this prompt explains what's happening in the right image **without repeating information already shown in the left image**. |
| `Left Relative Prompt`  | A prompt that describes the left sub-image **relative to the right sub-image**. This prompt explains what's happening in the left image given the context of the right image, without repeating details already included in the right image.                 |

**Note:** Both the left and right images contain the same main person, with the same clothing and appearance, but the backgrounds may differ, or the person may be doing different activities in each sub-image.

---

## Example Entries

### Example 1

```json
{
    "image_path": "person_data/img/0-1.png",
    "image_path_left": "person_data/sub_img/img_left/0_1_left.jpg",
    "image_path_right": "person_data/sub_img/img_right/0_1_right.jpg",
    "Right Relative Prompt": "He is setting up a tent at the campground, with trees in the background.",
    "Left Relative Prompt": "This lad is sitting by a campfire at a campground, looking into the flames."
}
```

### Example 2

```json
{
    "image_path": "person_data/img/0-3.png",
    "image_path_left": "person_data/sub_img/img_left/0_3_left.jpg",
    "image_path_right": "person_data/sub_img/img_right/0_3_right.jpg",
    "Right Relative Prompt": "He is setting up a tent at the campground, with trees in the background.",
    "Left Relative Prompt": "This lad is sitting by a campfire at a campground, looking into the flames."
}
```

---

## Key Explanations

* **`image_path`**: The path to the original person image generated by the model.
* **`image_path_left`** and **`image_path_right`**: Paths to the two sub-images. Each sub-image contains the same main person, but possibly in different backgrounds or performing different actions.
* **`Right Relative Prompt`**: A textual description for the right image, written relative to the left image (i.e., only describing what's new or different in the right image, assuming the left image's information is known).
* **`Left Relative Prompt`**: A textual description for the left image, written relative to the right image.

---

## Intended Use

This dataset was specifically designed for training models to generate new images of a reference person—ensuring the generated person matches the appearance and clothing of the given reference—while allowing changes to background or activity. Each image pair, together with the associated relative prompts, forms a training triplet for conditional person image generation tasks.

The dataset contains **470,664 pairs** of person images, leading to **941,328 triplets** for training.

## How to Unzip the Per-400K Dataset

After downloading the **Per-400K** dataset, you need to extract all image files from the provided zip archives to use the dataset normally.

This repository provides a script, **`unzip_files.py`**, which will automatically extract all zip packages in the dataset folders.

---

### **Usage**

1. **Make sure you have [Python 3.x](https://www.python.org/downloads/) and [`tqdm`](https://pypi.org/project/tqdm/) installed:**

   ```bash
   pip install tqdm
   ```

2. **Download the entire Per-400K dataset and place it at:**

   ```
   /path/to/Per-400k
   ```

   *(or modify the `root_dir` variable in the script to match your actual path)*

3. **Run the extraction script:**

   ```bash
   python unzip_files.py
   ```

   The script will automatically traverse all non-hidden folders under the dataset root and extract any zip files named like `batch_*.zip` or `all_files.zip` found in those directories.

---

### **Notes**

* **Default behavior:**
  The script will **extract** all files but **keep the original zip files** for backup.

* **If you want to automatically delete the original zip packages after extraction:**
  Open `unzip_files.py`, find this line:

  ```python
  # os.remove(zip_path)
  ```

  and **remove the `#` at the beginning** (i.e., uncomment it).
  This will cause the script to **delete the zip archive** after successful extraction.

